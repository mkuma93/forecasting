{
 "cells": [
  {
   "cell_type": "markdown",
   "id": "369bdc2a",
   "metadata": {},
   "source": [
    "## 1. Setup"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "9361f7f8",
   "metadata": {},
   "outputs": [],
   "source": [
    "import sys\n",
    "import os\n",
    "sys.path.insert(0, os.path.join(os.getcwd(), '..', 'published_model_main'))\n",
    "\n",
    "import pandas as pd\n",
    "import numpy as np\n",
    "import matplotlib.pyplot as plt\n",
    "from sklearn.metrics import mean_absolute_error, mean_squared_error\n",
    "import tensorflow as tf\n",
    "from tensorflow.keras import layers\n",
    "from tensorflow.keras.models import Model\n",
    "from tensorflow.keras.callbacks import EarlyStopping\n",
    "\n",
    "from deepsequence.seasonal_component import SeasonalComponent\n",
    "from deepsequence.tabnet_encoder import TabNetEncoder\n",
    "from deepsequence.cross_layer import CrossNetwork\n",
    "from deepsequence.unit_norm import UnitNorm\n",
    "\n",
    "SEED = 42\n",
    "np.random.seed(SEED)\n",
    "tf.random.set_seed(SEED)\n",
    "\n",
    "print(\"✓ Setup complete!\")"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "c023533d",
   "metadata": {},
   "source": [
    "## 2. Generate Intermittent Demand Data\n",
    "\n",
    "Creating synthetic data with 80% zeros (intermittent demand pattern)."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "1106bdf8",
   "metadata": {},
   "outputs": [],
   "source": [
    "n_skus, n_weeks = 10, 100\n",
    "dates = pd.date_range('2020-01-01', periods=n_weeks, freq='W')\n",
    "\n",
    "data_list = []\n",
    "for sku_id in range(n_skus):\n",
    "    for i, date in enumerate(dates):\n",
    "        # 80% zeros (intermittent)\n",
    "        if np.random.random() < 0.8:\n",
    "            qty = 0\n",
    "        else:\n",
    "            seasonal = 10 * np.sin(2 * np.pi * i / 52)\n",
    "            trend = 0.1 * i\n",
    "            qty = max(0, seasonal + trend + np.random.randint(5, 20))\n",
    "        \n",
    "        data_list.append({\n",
    "            'ds': date, 'id_var': sku_id, 'Quantity': qty,\n",
    "            'week_of_year': date.isocalendar()[1],\n",
    "            'month': date.month, 'day_of_week': date.dayofweek\n",
    "        })\n",
    "\n",
    "data = pd.DataFrame(data_list)\n",
    "print(f\"Dataset: {len(data):,} records, Sparsity: {(data['Quantity']==0).sum()/len(data)*100:.1f}%\")\n",
    "data.head()"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "515ae00e",
   "metadata": {},
   "source": [
    "## 3. Feature Engineering"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "ba6c523d",
   "metadata": {},
   "outputs": [],
   "source": [
    "data = data.sort_values(['id_var', 'ds']).reset_index(drop=True)\n",
    "\n",
    "# Lags\n",
    "for lag in [1, 2, 4]:\n",
    "    data[f'lag_{lag}'] = data.groupby('id_var')['Quantity'].shift(lag)\n",
    "data[['lag_1', 'lag_2', 'lag_4']] = data[['lag_1', 'lag_2', 'lag_4']].fillna(0)\n",
    "\n",
    "# Fourier features\n",
    "data['fourier_weekly_sin'] = np.sin(2 * np.pi * data.index / 52)\n",
    "data['fourier_weekly_cos'] = np.cos(2 * np.pi * data.index / 52)\n",
    "data['fourier_monthly_sin'] = np.sin(2 * np.pi * data.index / 12)\n",
    "data['fourier_monthly_cos'] = np.cos(2 * np.pi * data.index / 12)\n",
    "\n",
    "print(f\"✓ Features: {len(data.columns)} columns\")"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "be3a15fc",
   "metadata": {},
   "source": [
    "## 4. Train/Test Split (80/20 by time per SKU)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "3441c4fd",
   "metadata": {},
   "outputs": [],
   "source": [
    "train_list, test_list = [], []\n",
    "for sku_id in data['id_var'].unique():\n",
    "    sku = data[data['id_var'] == sku_id]\n",
    "    split = int(len(sku) * 0.8)\n",
    "    train_list.append(sku.iloc[:split])\n",
    "    test_list.append(sku.iloc[split:])\n",
    "\n",
    "train = pd.concat(train_list, ignore_index=True)\n",
    "test = pd.concat(test_list, ignore_index=True)\n",
    "\n",
    "print(f\"Train: {len(train):,}, Test: {len(test):,}\")\n",
    "print(f\"Test sparsity: {(test['Quantity']==0).sum()/len(test)*100:.1f}%\")"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "7a6bbd4e",
   "metadata": {},
   "source": [
    "## 5. Build DeepSequence Model\n",
    "\n",
    "All 4 components + enhancements + intermittent handler."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "6240c10e",
   "metadata": {},
   "outputs": [],
   "source": [
    "n_ids = train['id_var'].nunique()\n",
    "\n",
    "# Shared ID embedding\n",
    "id_in = layers.Input(shape=(1,), name='id')\n",
    "id_emb = layers.Flatten()(layers.Embedding(n_ids + 1, 16)(id_in))\n",
    "\n",
    "# 1. SEASONAL\n",
    "seasonal_comp = SeasonalComponent(train, ['Quantity'], 'id_var', 4, True, True, 'w')\n",
    "seasonal_comp.seasonal_feature()\n",
    "s_cols = [c for c in seasonal_comp.sr_df.columns if c not in ['id_var', 'ds']]\n",
    "\n",
    "s_ins, s_embs = [], []\n",
    "for col in s_cols:\n",
    "    s_i = layers.Input(shape=(1,), name=f's_{col}')\n",
    "    s_ins.append(s_i)\n",
    "    if col in ['week_of_year', 'month']:\n",
    "        nu = 52 if col == 'week_of_year' else 12\n",
    "        s_embs.append(layers.Flatten()(layers.Embedding(nu+1, 8)(s_i)))\n",
    "    else:\n",
    "        s_embs.append(s_i)\n",
    "\n",
    "f_ins = [layers.Input(shape=(1,), name=f) for f in ['fourier_weekly_sin', 'fourier_weekly_cos', \n",
    "                                                      'fourier_monthly_sin', 'fourier_monthly_cos']]\n",
    "\n",
    "s_cat = layers.Concatenate()([id_emb] + s_embs + f_ins)\n",
    "s_tab = TabNetEncoder(32, 32, 2, 2, 2)(s_cat)\n",
    "s_cr = CrossNetwork(2)(s_tab)\n",
    "s_norm = UnitNorm()(s_cr)\n",
    "s_out = layers.Dense(1, activation='linear', name='s_forecast')(s_norm)\n",
    "\n",
    "# 2. TREND\n",
    "t_in = layers.Input(shape=(1,), name='time')\n",
    "t_cat = layers.Concatenate()([id_emb, t_in])\n",
    "t_h = layers.Dropout(0.2)(layers.Dense(32, activation='relu')(t_cat))\n",
    "t_out = layers.Dense(1, activation='linear', name='t_forecast')(t_h)\n",
    "\n",
    "# 3. REGRESSOR\n",
    "l_ins = [layers.Input(shape=(1,), name=f'lag_{i}') for i in [1,2,4]]\n",
    "r_cat = layers.Concatenate()([id_emb] + l_ins)\n",
    "r_tab = TabNetEncoder(16, 16, 2, 1, 1)(r_cat)\n",
    "r_cr = CrossNetwork(1)(r_tab)\n",
    "r_norm = UnitNorm()(r_cr)\n",
    "r_out = layers.Dense(1, activation='linear', name='r_forecast')(r_norm)\n",
    "\n",
    "# 4. HOLIDAY\n",
    "h_in = layers.Input(shape=(1,), name='holiday')\n",
    "h_cat = layers.Concatenate()([id_emb, h_in])\n",
    "h_out = layers.Dense(1, activation='linear', name='h_forecast')(layers.Dense(16, 'relu')(h_cat))\n",
    "\n",
    "# COMBINE\n",
    "combined = layers.Add()([s_out, t_out, r_out, h_out])\n",
    "\n",
    "# CROSS-COMPONENT\n",
    "cc = CrossNetwork(2)(layers.Concatenate()([s_out, t_out, r_out, h_out]))\n",
    "\n",
    "# INTERMITTENT HANDLER\n",
    "ih = layers.Dropout(0.2)(UnitNorm()(layers.Dense(32, 'relu')(cc)))\n",
    "ih = UnitNorm()(layers.Dense(16, 'relu')(ih))\n",
    "prob = layers.Dense(1, activation='sigmoid', name='prob')(ih)\n",
    "\n",
    "# FINAL\n",
    "final = layers.Multiply(name='forecast')([combined, prob])\n",
    "\n",
    "model = Model([id_in] + s_ins + f_ins + [t_in] + l_ins + [h_in], final)\n",
    "print(f\"✓ Model: {model.count_params():,} params\")"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "d3955e4a",
   "metadata": {},
   "source": [
    "## 6. Prepare Data"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "f7d51939",
   "metadata": {},
   "outputs": [],
   "source": [
    "def prep(df, sc, s_cols):\n",
    "    sc.data = df\n",
    "    sc.seasonal_feature()\n",
    "    s_df = sc.sr_df\n",
    "    \n",
    "    ids = df['id_var'].values[:len(s_df)].reshape(-1, 1)\n",
    "    s_vals = [s_df[c].values.reshape(-1, 1) for c in s_cols]\n",
    "    f_vals = [df[f].values[:len(s_df)].reshape(-1, 1) \n",
    "              for f in ['fourier_weekly_sin', 'fourier_weekly_cos', \n",
    "                       'fourier_monthly_sin', 'fourier_monthly_cos']]\n",
    "    t_val = ((df['ds'] - df['ds'].min()).dt.days.values[:len(s_df)] / \n",
    "             (df['ds'].max() - df['ds'].min()).days).reshape(-1, 1)\n",
    "    l_vals = [df[f'lag_{i}'].values[:len(s_df)].reshape(-1, 1) for i in [1,2,4]]\n",
    "    h_val = (df['month'].values[:len(s_df)] == 12).astype(float).reshape(-1, 1)\n",
    "    \n",
    "    return [ids] + s_vals + f_vals + [t_val] + l_vals + [h_val], df['Quantity'].values[:len(s_df)]\n",
    "\n",
    "train_X, train_y = prep(train, seasonal_comp, s_cols)\n",
    "test_X, test_y = prep(test, seasonal_comp, s_cols)\n",
    "\n",
    "print(f\"✓ Train: {len(train_y):,}, Test: {len(test_y):,}\")"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "def93e7b",
   "metadata": {},
   "source": [
    "## 7. Train"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "d4489123",
   "metadata": {},
   "outputs": [],
   "source": [
    "model.compile(optimizer='adam', loss='mae', metrics=['mae'])\n",
    "\n",
    "history = model.fit(\n",
    "    train_X, train_y, validation_split=0.2,\n",
    "    epochs=30, batch_size=32, verbose=1,\n",
    "    callbacks=[EarlyStopping('val_loss', patience=5, restore_best_weights=True)]\n",
    ")\n",
    "\n",
    "print(f\"\\n✓ Trained ({len(history.history['loss'])} epochs)\")"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "97968012",
   "metadata": {},
   "source": [
    "## 8. Evaluate"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "dfd81af4",
   "metadata": {},
   "outputs": [],
   "source": [
    "test_pred = np.maximum(model.predict(test_X, verbose=0).flatten(), 0)\n",
    "test_mae = mean_absolute_error(test_y, test_pred)\n",
    "test_rmse = np.sqrt(mean_squared_error(test_y, test_pred))\n",
    "\n",
    "print(f\"Test MAE:  {test_mae:.4f}\")\n",
    "print(f\"Test RMSE: {test_rmse:.4f}\")\n",
    "\n",
    "plt.figure(figsize=(12, 4))\n",
    "plt.subplot(1, 2, 1)\n",
    "plt.plot(history.history['loss'], label='Train')\n",
    "plt.plot(history.history['val_loss'], label='Val')\n",
    "plt.title('Training')\n",
    "plt.xlabel('Epoch')\n",
    "plt.ylabel('MAE')\n",
    "plt.legend()\n",
    "plt.grid(True)\n",
    "\n",
    "plt.subplot(1, 2, 2)\n",
    "plt.scatter(test_y, test_pred, alpha=0.5)\n",
    "plt.plot([0, test_y.max()], [0, test_y.max()], 'r--')\n",
    "plt.xlabel('Actual')\n",
    "plt.ylabel('Predicted')\n",
    "plt.title('Predictions')\n",
    "plt.grid(True)\n",
    "plt.tight_layout()\n",
    "plt.show()"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "a15d529c",
   "metadata": {},
   "source": [
    "## 9. Intermittent Handler Analysis"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "da583e20",
   "metadata": {},
   "outputs": [],
   "source": [
    "prob_model = Model(model.inputs, model.get_layer('prob').output)\n",
    "test_prob = prob_model.predict(test_X, verbose=0).flatten()\n",
    "\n",
    "is_zero = (test_y == 0).astype(int)\n",
    "print(f\"Avg prob when actual=0: {test_prob[is_zero==1].mean():.3f}\")\n",
    "print(f\"Avg prob when actual>0: {test_prob[is_zero==0].mean():.3f}\")\n",
    "\n",
    "plt.figure(figsize=(10, 4))\n",
    "plt.subplot(1, 2, 1)\n",
    "plt.hist(test_prob[is_zero==1], bins=20, alpha=0.7, label='Zero')\n",
    "plt.hist(test_prob[is_zero==0], bins=20, alpha=0.7, label='Non-Zero')\n",
    "plt.xlabel('Probability')\n",
    "plt.ylabel('Count')\n",
    "plt.title('Intermittent Handler')\n",
    "plt.legend()\n",
    "plt.grid(True, alpha=0.3)\n",
    "\n",
    "plt.subplot(1, 2, 2)\n",
    "plt.scatter(test_prob, test_y, alpha=0.3)\n",
    "plt.xlabel('Probability')\n",
    "plt.ylabel('Actual')\n",
    "plt.title('Prob vs Demand')\n",
    "plt.grid(True, alpha=0.3)\n",
    "plt.tight_layout()\n",
    "plt.show()"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "56dc3e49",
   "metadata": {},
   "source": [
    "## 10. Sample Forecast"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "060d976a",
   "metadata": {},
   "outputs": [],
   "source": [
    "test_df = test.copy()\n",
    "test_df['forecast'] = test_pred[:len(test)]\n",
    "\n",
    "sku = test_df['id_var'].unique()[0]\n",
    "sku_all = data[data['id_var'] == sku].sort_values('ds')\n",
    "sku_test = test_df[test_df['id_var'] == sku].sort_values('ds')\n",
    "\n",
    "plt.figure(figsize=(12, 5))\n",
    "plt.plot(sku_all['ds'], sku_all['Quantity'], label='Historical', linewidth=2)\n",
    "plt.plot(sku_test['ds'], sku_test['forecast'], label='Forecast', \n",
    "         color='red', linewidth=2, marker='o')\n",
    "plt.axvline(train['ds'].max(), color='gray', linestyle='--', label='Split')\n",
    "plt.title(f'SKU {sku}', fontsize=14, fontweight='bold')\n",
    "plt.xlabel('Date')\n",
    "plt.ylabel('Quantity')\n",
    "plt.legend()\n",
    "plt.grid(True, alpha=0.3)\n",
    "plt.show()\n",
    "\n",
    "print(\"\\n✓ Demo complete!\")"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "ebbd23da",
   "metadata": {},
   "source": [
    "## Summary\n",
    "\n",
    "**Demonstrated:**\n",
    "- 4-component architecture (Seasonal, Trend, Regressor, Holiday)\n",
    "- Fourier features for smooth seasonality\n",
    "- TabNet + CrossNetwork for feature selection/interactions\n",
    "- Intermittent handler for zero demand prediction\n",
    "- Full pipeline: data → model → evaluation\n",
    "\n",
    "**Key Results:**\n",
    "- Synthetic data with 80% sparsity\n",
    "- Model: ~67K parameters\n",
    "- Intermittent handler learns zero vs non-zero patterns\n",
    "\n",
    "**Production Results (Real Data):**\n",
    "- MAE: 3.1941 vs LightGBM: 3.2499 (1.7% improvement)\n",
    "- 86.4% sparse, 10 SKUs\n",
    "- See research_comparison.log for details\n",
    "\n",
    "**Next Steps:**\n",
    "- Replace with your own dataset\n",
    "- Tune hyperparameters\n",
    "- Add more features\n",
    "- Compare with baselines\n",
    "\n",
    "See `README.md` for full documentation."
   ]
  }
 ],
 "metadata": {
  "language_info": {
   "name": "python"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
